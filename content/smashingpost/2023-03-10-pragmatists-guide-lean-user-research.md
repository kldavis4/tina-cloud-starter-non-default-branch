---
title: 'A Pragmatist’s Guide To Lean User Research'
slug: pragmatists-guide-lean-user-research
author: paul-boag
image: >-
  https://files.smashing.media/articles/pragmatists-guide-lean-user-research/pragmatists-guide-lean-user-research.jpg
date: 2023-03-10T08:00:00.000Z
summary: >-
  Even a small amount of user research can save so much time. Instead of telling you once again what the best practice is and adding to your imposter syndrome, let’s concentrate on some practical approaches to user research that we might be able to fit into our existing projects without being left disillusioned.
description: >-
  Instead of telling you once again what the best practice is and adding to your imposter syndrome, let’s concentrate on some practical approaches to user research that we might be able to fit into our existing projects without being left disillusioned.
categories:
  - Guides
  - User Research
  - User Experience
---

We don’t live in an ideal world. Most of us have too much work, too little time, and too small a budget. When it comes to digital projects, it seems like our clients or bosses always prioritize speed over quality.

To make matters worse, we read countless articles telling us how we should do things. These articles emphasize research and testing but do nothing more than leave us disillusioned and add to our imposter syndrome.

In this article, I want to try a different approach. Instead of telling you what the best practice is, I’ll explore some practical approaches to user research that we might be able to fit into our existing projects.

I know what you’re thinking: 

<blockquote>“I won’t be allowed to do research. I’ll be told there’s no time.”</blockquote>

So let’s start there.

## Lean User Research Saves Time Rather Than Costs It

The notion that all user research must take away from the available time for a project is flawed. Lean user research has the potential to save you time, especially on projects with multiple stakeholders.

Consider how much time is wasted on calls debating the best approach or in Figma endlessly revising the design because the client can’t make up their mind. Then there is the time of the other stakeholders, all of whom have to attend those meetings and provide feedback.

A small amount of user research can solve much of that. It can replace endless opinions, discussions, and revisions with data.

We don’t need to ask for extra time for research. Instead, we can replace some of those meetings with a quick survey or test and cut through all the discussion.

But what about the discovery you are supposed to do upfront? What about the research into your audience before you begin? Isn’t that best practice, and shouldn’t you be doing that?

Well, yes and no.

## What About Upfront Research?

Yes, [a discovery phase](https://boagworld.com/digital-strategy/discovery-phase/) is best practice. It is our chance to challenge our assumptions about the users and their needs. However, we don’t always get to do what we should, and not every discovery phase needs to take a lot of work.

If you’re not careful, discovery phases can be a little wasteful. General research into your audience and needs may not always provide applicable insights. That’s because it’s only once we start work that we learn what questions to ask upfront. Of course, by that point, you have already used time on the discovery phase, and stakeholders may be reluctant to do any more research.

Simply carrying out exercises like [customer journey mapping](https://www.smashingmagazine.com/2015/01/all-about-customer-journey-mapping/) because you’ve read that you should do it upfront is not a good enough reason when time and money are tight.

So, if time is tight, don’t feel like you have to do a full-blown discovery phase just because articles like this tell you to. Instead, start by collating what the organization already knows about the user and their needs. Most organizations know more than you think about their audience. Whether it’s personas produced by marketing, surveys run in the past, or analytics data, it can often just be a matter of gathering together what already exists.

Once you have done that, you will have a clearer picture of what is missing. If there are some significant and obvious gaps in your knowledge, then some upfront research is worthwhile. However, it might be that you have enough to start, leaving more time for user research as issues arise.

Either way,

{{% pull-quote %}}
Your focus should be on answering specific questions, not improving your general understanding of the user. 
{{% /pull-quote %}}

## Focus On Answering Specific Questions

User research can quickly become a time sink if not managed carefully. Adding more and more questions to surveys because “it would be interesting to know” will slow down the surveying process. Equally, you can waste hours simply watching user sessions back. While this context is helpful, it is better to conduct user research only when there is a specific question that needs answering.

{{< rimg href="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/1-hotjar-site-example.png" src="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/1-hotjar-site-example.png" width="800" height="542" sizes="100vw" caption="Watching user sessions can be enlightening. But, it is also highly time-consuming. (<a href='https://files.smashing.media/articles/pragmatists-guide-lean-user-research/1-hotjar-site-example.png'>Large preview</a>)" alt="Jotjar site example with a user session" >}}

For example, if you want to know why people aren’t buying on your website, run a one-question survey that asks why when people go to leave the site. Or, if stakeholders are concerned that users will miss a critical call to action, do a quick [5-second test](https://usabilityhub.com/guides/five-second-testing) to reassure them.

Focusing user research on answering these kinds of questions not only ensures a better result but also ensures that user research saves time. Without user research, discussions and debates around these topics can drag out and slow momentum. Additionally, by focusing user research on addressing a single question, it keeps it small and easy to incorporate into an existing project.

{{% pull-quote %}}
Many little bits of user research are easier to insert than a single significant discovery phase.
{{% /pull-quote %}}

Of course, this is only true if the types of user research you do are lightweight.

## Keep Your User Research Lightweight

When trying to keep our user research lean, tough decisions must be made. One of these is to **move away from facilitated research**, such as user interviews or usability testing, as they are too time-consuming.

Instead, we should focus on research that can be set up in minutes, provides results quickly, and can be understood at a glance. This leaves us primarily with surveys and unfacilitated testing.

{{% feature-panel %}}

### Run Quick And Dirty Surveys

Personally, I love quick surveys to resolve areas of disagreement or uncertainty. If in doubt, I argue, it’s best to ask the user. Just a few examples of surveys I have run recently include:

- Comparing two labels for a second on a website.
- Identifying tasks users wanted to complete on a website.
- Discovering why people weren’t signing up for a free trial.
- Assessing whether people understood an infographic.

I could go on, but you get the idea. Short, focused surveys can help answer questions quickly.

{{< rimg href="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/2-paul-boag-encourage-users-to-complete-call-action.png" src="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/2-paul-boag-encourage-users-to-complete-call-action.png" width="800" height="502" sizes="100vw" caption="A simple exit-intent survey can quickly answer a question such as why users are not buying. (<a href='https://files.smashing.media/articles/pragmatists-guide-lean-user-research/2-paul-boag-encourage-users-to-complete-call-action.png'>Large preview</a>)" alt="An example of an exit-intent survey on a site" >}}

Surveys are easy to create and depending on how you approach them, you can get results quickly. If time is more of a barrier than money, you can use an app like [Pollfish](https://www.notion.so/Lean-UX-Research-Smashing-Article-0c2fac4b81a645ca9189c8e974e2935b) to recruit the exact demographic of people you need for a few dollars per submission. You can usually get results in less than a day with only a few minutes of work to set up the survey.

{{< rimg href="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/3-pollfish-website-exaample-survey-audience.png" src="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/3-pollfish-website-exaample-survey-audience.png" width="800" height="587" sizes="100vw" caption="Survey tools like Pollfish will manage participant recruitment if you do not have time to wait. (<a href='https://files.smashing.media/articles/pragmatists-guide-lean-user-research/3-pollfish-website-exaample-survey-audience.png'>Large preview</a>)" alt="Screenshot from Pollfish website which states ‘buy survey responses straight from the source’" >}}

If money is an obstacle, consider sharing your survey on social media, a mailing list, or your website. You could even share it with random people who aren’t involved in the project if you’re desperate. At least you’d get an outside perspective.

When your questions are about a design approach you’ve produced, you can turn to unfacilitated testing.

{{% ad-panel-leaderboard %}}

### Try Some Unfaciliated Tests

Stakeholders often spend days debating and revising design concepts when quick tests could provide the answers they need. Generally, these design discussions revolve around four questions:

- Did users see it?
- Did users understand it?
- Can people use it?
- Will they like it?

Fortunately, there are quick tests that can help answer each of these questions.

#### Did Users See It?

If stakeholders are concerned that someone might miss a call to action or critical messaging, you can run a [5-Second Test](https://usabilityhub.com/guides/five-second-testing). This test presents users with a digital product, such as a website or app, for five seconds before asking what they saw. Tools like [Usability Hub](https://usabilityhub.com) and [Maze](https://maze.co) provide a URL for the test that you can share with participants, similar to how you would distribute a survey. If users recall seeing the element in question, you know everything is good.

#### Did Users Understand It?

A slight variation of the test can also be used to answer the second question: did users understand it? Show the user your design for 5 seconds, then ask them to describe what they saw in their own words. If they accurately describe the concept, you can be sure of your approach.

#### Can People Use It?

When it comes to the “can people use it?” question, you have two options.

If you have a prototype, you can run **unfacilitated usability testing** with a tool like Maze: 

1. Define the task you need to see people complete;
2. Provide Maze with the most direct route to complete the task;
3. Give participants the URL Maze provides.

Maze will give you aggregated data on how long it took people to complete the task and the number of mistakes they made.

{{< rimg href="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/4-maze-metrics-website-example.png" src="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/4-maze-metrics-website-example.png" width="800" height="620" sizes="100vw" caption="Maze provides aggregated data, so you are not forced to watch every user complete a task. (<a href='https://files.smashing.media/articles/pragmatists-guide-lean-user-research/4-maze-metrics-website-example.png'>Large preview</a>)" alt="A screenshot from Maze website with automated metrics" >}}

If you don’t have a prototype, the alternative is to do a [first-click test](https://usabilityhub.com/guides/first-click-testing):

1. Show users a mockup of your website or app;
2. Ask where they would click to complete a specific task.

According to a [usability study by Bob Bailey and Cari Wolfson](https://usabilityhub.com/guides/first-click-testing), if the first click is correct, users have an 87% chance of completing the action correctly, compared to just 46% if the first click is wrong. So, if people get their first-click correct, you can be reasonably confident they can successfully complete the task.

Usability Hub can help you run your first-click test. They will provide a heat map showing the aggregated results of where everyone clicked, so you don’t need to analyze the results manually. This allows you to get answers almost immediately.

{{< rimg href="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/5-usability-hub-example.png" src="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/5-usability-hub-example.png" width="800" height="662" sizes="100vw" caption="Usability Hub provides first-click test results as a heatmap for quick reference. (<a href='https://files.smashing.media/articles/pragmatists-guide-lean-user-research/5-usability-hub-example.png'>Large preview</a>)" alt="Usability Hub example with a heatmap" >}}

#### Will People Like It?

The final question is, “Will people like it?” This is not easy to answer, as different stakeholders may have different opinions about what works.

To resolve this, I usually conduct a [preference test](https://usabilityhub.com/guides/preference-testing) or, ideally, [a semantic differential survey](https://boagworld.com/design/testing-design/#the-semantic-differential-survey).

First, I agree with stakeholders on the associations we want users to have with the design. These may include words like professional, friendly, inspiring, or serious.

In a **semantic differential survey**, users can then rate the design against those words. If the design scores well, we can be confident it will generate the desired response.

{{< rimg href="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/6-semantic-survey-keyword-peformance.jpg" src="https://files.smashing.media/articles/pragmatists-guide-lean-user-research/6-semantic-survey-keyword-peformance.jpg" width="800" height="458" sizes="100vw" caption="A semantic differential survey is an excellent way of seeing how your site is performing against your chosen keywords. (<a href='https://files.smashing.media/articles/pragmatists-guide-lean-user-research/6-semantic-survey-keyword-peformance.jpg'>Large preview</a>)" alt="A semantic survey with a keyword performance" >}}

{{% ad-panel-leaderboard %}}

## A Pragmatic Approach

I know this post will make user researchers uncomfortable, and I can fully understand why. The results you get back will be far from perfect and could possibly lead to false conclusions. However, it is better than the alternative. Resolving design decisions through internal discussion is always going to be inferior to getting user feedback.

This kind of lean user research can also be a great starting point for bigger things. If you can add even some user research to the process, stakeholders can start to see its benefits, and it can lead to bigger things.

Some may choose to pick holes in your approach, suggesting that you aren’t testing with the right people or with a big enough audience. They are, of course, correct. However, this provides you with an opportunity to point out you would happily do more research if only the time and budget were made available!

### Further Reading On SmashingMag

- “[How To Build Strong Customer Relationships For User Research](https://www.smashingmagazine.com/2023/01/build-strong-customer-relationships-user-research/)”, Renaissance Rachel
- “[How To Build An Ethical User Research Practice At Any Organization](https://www.smashingmagazine.com/2021/08/ethical-user-research-practice/)”, Devin Harold
- “[Eye-Tracking In Mobile UX Research](https://www.smashingmagazine.com/2021/10/eye-tracking-mobile-ux-research/)”, Mariana Macedo
- “[A Comprehensive Guide To UX Research](https://www.smashingmagazine.com/2018/01/comprehensive-guide-ux-research/)”, Christopher Murphy

{{< signature "yk, il" >}}
